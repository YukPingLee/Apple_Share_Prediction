{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e478fc1",
   "metadata": {},
   "source": [
    "### Project: Apple Share Price Prediction (Part 2)\n",
    "Aims: predict the next 10 days (2 weeks) share price based on the last 5 years data\n",
    "\n",
    "Features used: \n",
    "- Open Price\n",
    "- High Price\n",
    "- Low Price\n",
    "- Volume, IXIC (NASDAQ Index)\n",
    "- GSPC (S&P 500 Index)\n",
    "- VIX (Volatility Index)\n",
    "- DX-Y.NYB (US Dollor Index)\n",
    "- TNX (US Treasury Yield)\n",
    "- SOX (PHLX Semiconductor Index)\n",
    "\n",
    "Note: Only using the closed prices for all other index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba8769",
   "metadata": {},
   "source": [
    "# Note: TensorFlow is incompatible with Python 3.12, need to be Python 3.10 or 3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310b3e0",
   "metadata": {},
   "source": [
    "### Model A1: Feed-Forward Neural Network (MLP) with PyTorch (not in this file)\n",
    "\n",
    "### Model A2: Feed-Forward Neural Network (MLP) with TensorFlow and Karas (in this file)\n",
    "\n",
    "### Model B: LSTM/Sequence Model (not in this file)\n",
    "\n",
    "### Model C: Transformer Model (not in this file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60c7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/xjs_s57d66dc3cnb0p3gwv180000gn/T/ipykernel_30564/3499833742.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  others_data = yf.download(tickers, period = \"5y\")[\"Close\"] # Only using the Close Prices for all indexes\n",
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "apple = yf.Ticker(\"AAPL\")\n",
    "apple_data = apple.history(period = \"5y\")\n",
    "tickers = [ \"^IXIC\", \"^GSPC\", \"DJI\", \"^VIX\", \"DX-Y.NYB\", \"^TNX\", \"^SOX\"]\n",
    "others_data = yf.download(tickers, period = \"5y\")[\"Close\"] # Only using the Close Prices for all indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1baf99",
   "metadata": {},
   "source": [
    "### Filling the missing value with previous available values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370ac1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            0\n",
       "High            0\n",
       "Low             0\n",
       "Close           0\n",
       "Volume          0\n",
       "Dividends       0\n",
       "Stock Splits    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_data = apple_data.ffill()\n",
    "\n",
    "# Checking if there is any missing value in apple_data\n",
    "apple_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ade44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "DJI         966\n",
       "DX-Y.NYB      0\n",
       "^GSPC         3\n",
       "^IXIC         3\n",
       "^SOX          3\n",
       "^TNX          2\n",
       "^VIX          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_data.ffill()\n",
    "others_data.isna().sum()\n",
    "\n",
    "# Note too many missing values in DJI, dropping the DJI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3fbca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "others_data.drop(columns = ['DJI'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7449ac5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "DX-Y.NYB    0\n",
       "^GSPC       3\n",
       "^IXIC       3\n",
       "^SOX        3\n",
       "^TNX        2\n",
       "^VIX        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e23755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>DX-Y.NYB</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^IXIC</th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^TNX</th>\n",
       "      <th>^VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-14</th>\n",
       "      <td>90.709999</td>\n",
       "      <td>3647.489990</td>\n",
       "      <td>12440.040039</td>\n",
       "      <td>2736.250000</td>\n",
       "      <td>0.892</td>\n",
       "      <td>24.719999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-15</th>\n",
       "      <td>90.470001</td>\n",
       "      <td>3694.620117</td>\n",
       "      <td>12595.059570</td>\n",
       "      <td>2774.790039</td>\n",
       "      <td>0.923</td>\n",
       "      <td>22.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-16</th>\n",
       "      <td>90.449997</td>\n",
       "      <td>3701.169922</td>\n",
       "      <td>12658.190430</td>\n",
       "      <td>2773.419922</td>\n",
       "      <td>0.920</td>\n",
       "      <td>22.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-17</th>\n",
       "      <td>89.820000</td>\n",
       "      <td>3722.479980</td>\n",
       "      <td>12764.750000</td>\n",
       "      <td>2778.139893</td>\n",
       "      <td>0.930</td>\n",
       "      <td>21.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-18</th>\n",
       "      <td>90.019997</td>\n",
       "      <td>3709.409912</td>\n",
       "      <td>12755.639648</td>\n",
       "      <td>2764.739990</td>\n",
       "      <td>0.948</td>\n",
       "      <td>21.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-08</th>\n",
       "      <td>99.089996</td>\n",
       "      <td>6846.509766</td>\n",
       "      <td>23545.900391</td>\n",
       "      <td>7375.220215</td>\n",
       "      <td>4.172</td>\n",
       "      <td>16.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-09</th>\n",
       "      <td>99.220001</td>\n",
       "      <td>6840.509766</td>\n",
       "      <td>23576.490234</td>\n",
       "      <td>7372.509766</td>\n",
       "      <td>4.186</td>\n",
       "      <td>16.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-10</th>\n",
       "      <td>98.790001</td>\n",
       "      <td>6886.680176</td>\n",
       "      <td>23654.150391</td>\n",
       "      <td>7467.490234</td>\n",
       "      <td>4.164</td>\n",
       "      <td>15.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-11</th>\n",
       "      <td>98.349998</td>\n",
       "      <td>6901.000000</td>\n",
       "      <td>23593.859375</td>\n",
       "      <td>7411.479980</td>\n",
       "      <td>4.141</td>\n",
       "      <td>14.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-12</th>\n",
       "      <td>98.415001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.180</td>\n",
       "      <td>15.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker       DX-Y.NYB        ^GSPC         ^IXIC         ^SOX   ^TNX  \\\n",
       "Date                                                                   \n",
       "2020-12-14  90.709999  3647.489990  12440.040039  2736.250000  0.892   \n",
       "2020-12-15  90.470001  3694.620117  12595.059570  2774.790039  0.923   \n",
       "2020-12-16  90.449997  3701.169922  12658.190430  2773.419922  0.920   \n",
       "2020-12-17  89.820000  3722.479980  12764.750000  2778.139893  0.930   \n",
       "2020-12-18  90.019997  3709.409912  12755.639648  2764.739990  0.948   \n",
       "...               ...          ...           ...          ...    ...   \n",
       "2025-12-08  99.089996  6846.509766  23545.900391  7375.220215  4.172   \n",
       "2025-12-09  99.220001  6840.509766  23576.490234  7372.509766  4.186   \n",
       "2025-12-10  98.790001  6886.680176  23654.150391  7467.490234  4.164   \n",
       "2025-12-11  98.349998  6901.000000  23593.859375  7411.479980  4.141   \n",
       "2025-12-12  98.415001          NaN           NaN          NaN  4.180   \n",
       "\n",
       "Ticker           ^VIX  \n",
       "Date                   \n",
       "2020-12-14  24.719999  \n",
       "2020-12-15  22.889999  \n",
       "2020-12-16  22.500000  \n",
       "2020-12-17  21.930000  \n",
       "2020-12-18  21.570000  \n",
       "...               ...  \n",
       "2025-12-08  16.660000  \n",
       "2025-12-09  16.930000  \n",
       "2025-12-10  15.770000  \n",
       "2025-12-11  14.850000  \n",
       "2025-12-12  15.020000  \n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_data.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326d4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "others_data = others_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39334a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "DX-Y.NYB    0\n",
       "^GSPC       0\n",
       "^IXIC       0\n",
       "^SOX        0\n",
       "^TNX        0\n",
       "^VIX        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc47bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America/New_York\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(apple_data.index.tz)  \n",
    "print(others_data.index.tz)\n",
    "\n",
    "# Comment: apple_data times are timezone-awared while others_data times are timezone-naive (no timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5426ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the times in apple_data to timezone-naive\n",
    "\n",
    "apple_data.index = apple_data.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0bf6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = apple_data.join(others_data, how = \"inner\")\n",
    "full_df.drop(columns = [\"Dividends\", \"Stock Splits\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038acb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94862641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DX-Y.NYB</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^IXIC</th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^TNX</th>\n",
       "      <th>^VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-11-28</th>\n",
       "      <td>277.260010</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>275.989990</td>\n",
       "      <td>278.850006</td>\n",
       "      <td>20135600</td>\n",
       "      <td>99.459999</td>\n",
       "      <td>6849.089844</td>\n",
       "      <td>23365.689453</td>\n",
       "      <td>7025.149902</td>\n",
       "      <td>4.017</td>\n",
       "      <td>16.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-01</th>\n",
       "      <td>278.010010</td>\n",
       "      <td>283.420013</td>\n",
       "      <td>276.140015</td>\n",
       "      <td>283.100006</td>\n",
       "      <td>46587700</td>\n",
       "      <td>99.410004</td>\n",
       "      <td>6812.629883</td>\n",
       "      <td>23275.919922</td>\n",
       "      <td>7020.529785</td>\n",
       "      <td>4.096</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-02</th>\n",
       "      <td>283.000000</td>\n",
       "      <td>287.399994</td>\n",
       "      <td>282.630005</td>\n",
       "      <td>286.190002</td>\n",
       "      <td>53669500</td>\n",
       "      <td>99.360001</td>\n",
       "      <td>6829.370117</td>\n",
       "      <td>23413.669922</td>\n",
       "      <td>7149.470215</td>\n",
       "      <td>4.086</td>\n",
       "      <td>16.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-03</th>\n",
       "      <td>286.200012</td>\n",
       "      <td>288.619995</td>\n",
       "      <td>283.299988</td>\n",
       "      <td>284.149994</td>\n",
       "      <td>43538700</td>\n",
       "      <td>98.849998</td>\n",
       "      <td>6849.720215</td>\n",
       "      <td>23454.089844</td>\n",
       "      <td>7280.509766</td>\n",
       "      <td>4.057</td>\n",
       "      <td>16.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-04</th>\n",
       "      <td>284.100006</td>\n",
       "      <td>284.730011</td>\n",
       "      <td>278.589996</td>\n",
       "      <td>280.700012</td>\n",
       "      <td>43989100</td>\n",
       "      <td>98.989998</td>\n",
       "      <td>6857.120117</td>\n",
       "      <td>23505.140625</td>\n",
       "      <td>7215.970215</td>\n",
       "      <td>4.108</td>\n",
       "      <td>15.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-05</th>\n",
       "      <td>280.540009</td>\n",
       "      <td>281.140015</td>\n",
       "      <td>278.049988</td>\n",
       "      <td>278.779999</td>\n",
       "      <td>47265800</td>\n",
       "      <td>98.989998</td>\n",
       "      <td>6870.399902</td>\n",
       "      <td>23578.130859</td>\n",
       "      <td>7294.839844</td>\n",
       "      <td>4.139</td>\n",
       "      <td>15.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-08</th>\n",
       "      <td>278.130005</td>\n",
       "      <td>279.670013</td>\n",
       "      <td>276.149994</td>\n",
       "      <td>277.890015</td>\n",
       "      <td>38211800</td>\n",
       "      <td>99.089996</td>\n",
       "      <td>6846.509766</td>\n",
       "      <td>23545.900391</td>\n",
       "      <td>7375.220215</td>\n",
       "      <td>4.172</td>\n",
       "      <td>16.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-09</th>\n",
       "      <td>278.160004</td>\n",
       "      <td>280.029999</td>\n",
       "      <td>276.920013</td>\n",
       "      <td>277.179993</td>\n",
       "      <td>32193300</td>\n",
       "      <td>99.220001</td>\n",
       "      <td>6840.509766</td>\n",
       "      <td>23576.490234</td>\n",
       "      <td>7372.509766</td>\n",
       "      <td>4.186</td>\n",
       "      <td>16.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-10</th>\n",
       "      <td>277.750000</td>\n",
       "      <td>279.750000</td>\n",
       "      <td>276.440002</td>\n",
       "      <td>278.779999</td>\n",
       "      <td>33038300</td>\n",
       "      <td>98.790001</td>\n",
       "      <td>6886.680176</td>\n",
       "      <td>23654.150391</td>\n",
       "      <td>7467.490234</td>\n",
       "      <td>4.164</td>\n",
       "      <td>15.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-11</th>\n",
       "      <td>279.100006</td>\n",
       "      <td>279.589996</td>\n",
       "      <td>273.809998</td>\n",
       "      <td>278.029999</td>\n",
       "      <td>33207600</td>\n",
       "      <td>98.349998</td>\n",
       "      <td>6901.000000</td>\n",
       "      <td>23593.859375</td>\n",
       "      <td>7411.479980</td>\n",
       "      <td>4.141</td>\n",
       "      <td>14.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2025-11-28  277.260010  279.000000  275.989990  278.850006  20135600   \n",
       "2025-12-01  278.010010  283.420013  276.140015  283.100006  46587700   \n",
       "2025-12-02  283.000000  287.399994  282.630005  286.190002  53669500   \n",
       "2025-12-03  286.200012  288.619995  283.299988  284.149994  43538700   \n",
       "2025-12-04  284.100006  284.730011  278.589996  280.700012  43989100   \n",
       "2025-12-05  280.540009  281.140015  278.049988  278.779999  47265800   \n",
       "2025-12-08  278.130005  279.670013  276.149994  277.890015  38211800   \n",
       "2025-12-09  278.160004  280.029999  276.920013  277.179993  32193300   \n",
       "2025-12-10  277.750000  279.750000  276.440002  278.779999  33038300   \n",
       "2025-12-11  279.100006  279.589996  273.809998  278.029999  33207600   \n",
       "\n",
       "             DX-Y.NYB        ^GSPC         ^IXIC         ^SOX   ^TNX   ^VIX  \n",
       "Date                                                                         \n",
       "2025-11-28  99.459999  6849.089844  23365.689453  7025.149902  4.017  16.35  \n",
       "2025-12-01  99.410004  6812.629883  23275.919922  7020.529785  4.096  17.24  \n",
       "2025-12-02  99.360001  6829.370117  23413.669922  7149.470215  4.086  16.59  \n",
       "2025-12-03  98.849998  6849.720215  23454.089844  7280.509766  4.057  16.08  \n",
       "2025-12-04  98.989998  6857.120117  23505.140625  7215.970215  4.108  15.78  \n",
       "2025-12-05  98.989998  6870.399902  23578.130859  7294.839844  4.139  15.41  \n",
       "2025-12-08  99.089996  6846.509766  23545.900391  7375.220215  4.172  16.66  \n",
       "2025-12-09  99.220001  6840.509766  23576.490234  7372.509766  4.186  16.93  \n",
       "2025-12-10  98.790001  6886.680176  23654.150391  7467.490234  4.164  15.77  \n",
       "2025-12-11  98.349998  6901.000000  23593.859375  7411.479980  4.141  14.85  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a535fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full_df[\"Close\"]\n",
    "X = full_df.drop(columns = [\"Close\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626402b",
   "metadata": {},
   "source": [
    "### Preprocess the data\n",
    "\n",
    "Putting 30 days of data into 1 row as X ('Open', 'High', 'Low', 'Volume', 'DX-Y.NYB', '^GSPC', '^IXIC', '^SOX', '^TNX', '^VIX'), the next 10 days data (\"Close\") as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1daae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Need create an overlapping window for X (30 days) to predict y (10 days)\n",
    "# Reshape the whole dataset such that X = [[day1],[day2],....,[day30]], [day2,....,day31], y = [day31,....,day40], [day32,...,day41]\n",
    "\n",
    "# Window 1 (t = 0 → 4):\n",
    "# X₀ = [100, 102, 101, 103, 104]\n",
    "# y₀ = next 10 days\n",
    "\n",
    "# Window 2 (t = 1 → 5):\n",
    "# X₁ = [102, 101, 103, 104, 106]\n",
    "# y₁ = next 10 days\n",
    "\n",
    "window_x = 30\n",
    "window_y = 10\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "cols = ['Open', 'High', 'Low', 'Volume', 'DX-Y.NYB', '^GSPC', '^IXIC', '^SOX', '^TNX', '^VIX']\n",
    "\n",
    "# range(30,3200) creates a range object starting from 30,31,32,......3199\n",
    "\n",
    "# full_df[col].iloc[i-window:i].values return list of arrays wirh each row treated as an array\n",
    "\n",
    "for i in range(window_x, len(full_df) - window_y + 1):\n",
    "    X.append(full_df[cols].iloc[i-window_x : i].values)\n",
    "    y.append(full_df[[\"Close\"]].iloc[i:i + window_y].values)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eabe24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X.shape[0] #1206 rows\n",
    "window_x = X.shape[1] # 30 days of data in 1 row\n",
    "num_features = X.shape[2] # 10 features per day\n",
    "\n",
    "# Flatten X,now there are 1206 rows, with each row having 300 values (10 features * 30 days)\n",
    "X = X.reshape(num_samples, window_x * num_features)\n",
    "\n",
    "\n",
    "# Flatten y\n",
    "y = y.reshape(y.shape[0], y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f08b3dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5154d5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84554e",
   "metadata": {},
   "source": [
    "### Scale the data\n",
    "\n",
    "### MLP: Standard Scaler, inputs centered at around 0 to prevent gradient explodes or vanishes\n",
    "Gradient vanishing means during backpropagation the gradients become extremely small as they move backward thru the network, resuiting in model learning very slow or not learning at all.\n",
    "\n",
    "Gradient explosion means that the gradient become extremely large, they model jumps around instead of learning gradually.\n",
    "\n",
    "### LSTM: MinMaxScaler\n",
    "### Transformer: MinMaxScaler\n",
    "LSTM and Transformer contain sigmoid and softmax, which break when values arenot bounded.\n",
    "\n",
    "There will be some extreme values after standard scaling, e.g. -3, -5, -7\n",
    "\n",
    "LSTM input gate: sigmoid, sigmoid(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "LSTM forget gate: sigmoid\n",
    "\n",
    "LSTM output gate: sigmoid\n",
    "\n",
    "LSTM candidate state: tanh, tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "\n",
    "Transformer self-attention: Attention = softmax(QKᵀ / sqrt(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009ef65",
   "metadata": {},
   "source": [
    "### Model A2 - Feed-Forward Neural Network (MLP) with TensorFlow and Karas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77527a53",
   "metadata": {},
   "source": [
    "### Split the training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1db4cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set = first 70%, validation set = next 15%, test set = next 15%\n",
    "# Note: 80-10-10 fails when the validation set is too small to be reliable.\n",
    "n = len(X)\n",
    "train_end = int(0.7 * n)\n",
    "validation_end = int(0.85 * n)\n",
    "\n",
    "X_train = X[:train_end]\n",
    "X_validation = X[train_end:validation_end]\n",
    "X_test = X[validation_end:]\n",
    "\n",
    "y_train = y[:train_end]\n",
    "y_validation = y[train_end:validation_end]\n",
    "y_test  = y[validation_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fa9bf",
   "metadata": {},
   "source": [
    "### Scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "635ba8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to scale the training, validation and test data seperately such that there is no data leakage\n",
    "# Scale X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "scaler_X.fit(X_train) # fit() learns the statistic from your training data, i.e. means and SDs\n",
    "\n",
    "scaled_X_train_mlp = scaler_X.transform(X_train) # transform() used the learned statistics to apply the scaling\n",
    "\n",
    "scaled_X_validation_mlp  = scaler_X.transform(X_validation) # It uses the learned means and SDs to scale the test data\n",
    "\n",
    "scaled_X_test_mlp  = scaler_X.transform(X_test) # It uses the learned means and SDs to scale the test data\n",
    "\n",
    "# Scale y\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "scaler_y.fit(y_train) \n",
    "\n",
    "scaled_y_train_mlp = scaler_y.transform(y_train)\n",
    "\n",
    "scaled_y_validation_mlp = scaler_y.transform(y_validation)\n",
    "\n",
    "scaled_y_test_mlp = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9edfda",
   "metadata": {},
   "source": [
    "### Transfrom the training and testing datasets (both X and y) into tensors (must do before passing them into the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11d3244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 00:55:54.212721: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-12-13 00:55:54.212974: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-12-13 00:55:54.213058: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-12-13 00:55:54.213550: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-13 00:55:54.213569: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# torch.tensor() is equivalent to tf.convert_to_tensor()\n",
    "# For NNs, you must convert to float32\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(scaled_X_train_mlp, dtype = tf.float32)\n",
    "\n",
    "X_validation_tensor = tf.convert_to_tensor(scaled_X_validation_mlp, dtype = tf.float32)\n",
    "\n",
    "X_test_tensor = tf.convert_to_tensor(scaled_X_test_mlp, dtype = tf.float32)\n",
    "\n",
    "y_train_tensor = tf.convert_to_tensor(scaled_y_train_mlp, dtype = tf.float32)\n",
    "\n",
    "y_validation_tensor = tf.convert_to_tensor(scaled_y_validation_mlp, dtype = tf.float32)\n",
    "\n",
    "y_test_tensor = tf.convert_to_tensor(scaled_y_test_mlp, dtype = tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b1679",
   "metadata": {},
   "source": [
    "### Create Datasets and and load train_dataset and val_dataset (for scalability and performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529d408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset.from_tensor_slices() takes the full tensors X, and y, splits them into individual samples, creates pairs(X_i, y_i)\n",
    "# .prefetch(tf.data.AUTOTUNE): GPU does not wait for data, while GPU trains on batch N, CPU prepares batch N + 1\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_validation_tensor, y_validation_tensor)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c53dd",
   "metadata": {},
   "source": [
    "#### Dynamic MLP class with Keras \n",
    "- better than using Sequential() becasue it gives you more control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74da64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# input_dim = 300\n",
    "\n",
    "# model = models.Sequential([\n",
    "#         layers.Input(shape = (input_dim,)),\n",
    "#         layers.Dense(128, activation = \"gelu\"),\n",
    "#         layers.Dense(128, activation = \"gelu\"),\n",
    "#         layers.Dense(10, activation = \"linear\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleMLP(tf.keras.Model): # kf.keras.Model is the parent class\n",
    "    def __init__(self, input_dim, hidden_layers, activations, dropouts, output_dim):\n",
    "        super().__init__()  # super().__init__() call the constructor(__init__) of the parent class, the FlexibleMLP gets all public methods and behaviours (e.g. self.*)\n",
    "\n",
    "        if not (len(hidden_layers) == len(activations) == len(dropouts)):\n",
    "            raise ValueError(\"Lengths must match\")\n",
    "\n",
    "        act_map = {\n",
    "            \"relu\": tf.keras.layers.ReLU(),\n",
    "            \"gelu\": tf.keras.layers.GELU(),\n",
    "            \"tanh\": tf.keras.layers.Activation(\"tanh\"),\n",
    "            \"sigmoid\": tf.keras.layers.Activation(\"sigmoid\"),\n",
    "            \"elu\": tf.keras.layers.ELU(),\n",
    "        }\n",
    "\n",
    "        self.layers_list = []\n",
    "\n",
    "        for h, act, d in zip(hidden_layers, activations, dropouts):\n",
    "            self.layers_list.append(tf.keras.layers.Dense(h))\n",
    "            self.layers_list.append(act_map[act]) # Note: activation function is applied after the neuron, which decided whether there will be output passed to the next Dense layer (if not dropout)\n",
    "            if d > 0:\n",
    "                self.layers_list.append(tf.keras.layers.Dropout(d))\n",
    "\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for layer in self.layers_list:\n",
    "            if isinstance(layer, tf.keras.layers.Dropout):\n",
    "                x = layer(x, training=training)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cec1ae",
   "metadata": {},
   "source": [
    "### Use Optuna to find the best hyperparameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "728b4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
    "    base_units = trial.suggest_int(\"base_units\", 32, 512)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2, log = True)\n",
    "\n",
    "    hidden_layers = []\n",
    "    activations = []\n",
    "    dropouts = []\n",
    "\n",
    "    units = base_units\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        hidden_layers.append(units)\n",
    "\n",
    "        activations.append(\n",
    "            trial.suggest_categorical(\n",
    "                f\"activation_l{i}\",\n",
    "                [\"relu\", \"gelu\", \"tanh\", \"elu\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dropouts.append(\n",
    "            trial.suggest_float(\n",
    "                f\"dropout_l{i}\",\n",
    "                0.0, 0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "        units = max(units // 2, 16)  # funnel\n",
    "\n",
    "    model = FlexibleMLP(\n",
    "        input_dim=X_train_tensor.shape[1],\n",
    "        hidden_layers=hidden_layers,\n",
    "        activations=activations,\n",
    "        dropouts=dropouts,\n",
    "        output_dim=1\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=50,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                patience=5,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return min(history.history[\"val_loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 01:29:03,288] A new study created in memory with name: no-name-a3cc1dd1-2610-4e6e-a626-a417ba376ea2\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f1669bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_value\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/study.py:134\u001b[0m, in \u001b[0;36mStudy.best_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbest_value\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the best objective value in the study.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     best_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m best_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_value\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/study.py:156\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbest_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrozenTrial:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the best trial in the study.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/study.py:308\u001b[0m, in \u001b[0;36mStudy._get_best_trial\u001b[0;34m(self, deepcopy)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m constraints \u001b[38;5;241m=\u001b[39m best_trial\u001b[38;5;241m.\u001b[39msystem_attrs\u001b[38;5;241m.\u001b[39mget(_CONSTRAINTS_KEY)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/storages/_in_memory.py:252\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    249\u001b[0m best_trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mbest_trial_id\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trials are completed yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mdirections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b398b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 22:31:55.834328: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-12-12 22:31:55.834362: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-12-12 22:31:55.834368: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-12-12 22:31:55.834398: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-12 22:31:55.834407: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "input_dim = 300\n",
    "model = models.Sequential([\n",
    "        layers.Input(shape = (input_dim,)),\n",
    "        layers.Dense(128, activation = \"gelu\"),\n",
    "        layers.Dense(128, activation = \"gelu\"),\n",
    "        layers.Dense(10, activation = \"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e761f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
